{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "74f2ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error as MSE, r2_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score as RMSE \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from feature_engine.imputation import MeanMedianImputer\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "from feature_engine.wrappers import SklearnTransformerWrapper\n",
    "from feature_engine.encoding import OneHotEncoder, OrdinalEncoder, DecisionTreeEncoder\n",
    "from feature_engine import encoding as ce\n",
    "from feature_engine.encoding import WoEEncoder\n",
    "from feature_engine.encoding import RareLabelEncoder\n",
    "from feature_engine.imputation import CategoricalImputer\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "from feature_engine.discretisation import EqualFrequencyDiscretiser, EqualWidthDiscretiser \n",
    "from feature_engine.encoding import CountFrequencyEncoder\n",
    "from feature_engine.selection import DropConstantFeatures, DropDuplicateFeatures \n",
    "    from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5d6fa2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14115</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10084</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>307000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10382</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>350</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>129900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7420</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>11200</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>129500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>11924</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12968</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10652</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "      <td>279500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10920</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdWo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>157000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>45</td>\n",
       "      <td>RM</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6120</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>132000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11241</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>90</td>\n",
       "      <td>RL</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10791</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shed</td>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>13695</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7560</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>139000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0    1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1    2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2    3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3    4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4    5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "5    6          50       RL         85.0    14115   Pave   NaN      IR1   \n",
       "6    7          20       RL         75.0    10084   Pave   NaN      Reg   \n",
       "7    8          60       RL          NaN    10382   Pave   NaN      IR1   \n",
       "8    9          50       RM         51.0     6120   Pave   NaN      Reg   \n",
       "9   10         190       RL         50.0     7420   Pave   NaN      Reg   \n",
       "10  11          20       RL         70.0    11200   Pave   NaN      Reg   \n",
       "11  12          60       RL         85.0    11924   Pave   NaN      IR1   \n",
       "12  13          20       RL          NaN    12968   Pave   NaN      IR2   \n",
       "13  14          20       RL         91.0    10652   Pave   NaN      IR1   \n",
       "14  15          20       RL          NaN    10920   Pave   NaN      IR1   \n",
       "15  16          45       RM         51.0     6120   Pave   NaN      Reg   \n",
       "16  17          20       RL          NaN    11241   Pave   NaN      IR1   \n",
       "17  18          90       RL         72.0    10791   Pave   NaN      Reg   \n",
       "18  19          20       RL         66.0    13695   Pave   NaN      Reg   \n",
       "19  20          20       RL         70.0     7560   Pave   NaN      Reg   \n",
       "\n",
       "   LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "5          Lvl    AllPub  ...        0    NaN  MnPrv        Shed     700   \n",
       "6          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "7          Lvl    AllPub  ...        0    NaN    NaN        Shed     350   \n",
       "8          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "9          Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "10         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "11         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "12         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "13         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "14         Lvl    AllPub  ...        0    NaN   GdWo         NaN       0   \n",
       "15         Lvl    AllPub  ...        0    NaN  GdPrv         NaN       0   \n",
       "16         Lvl    AllPub  ...        0    NaN    NaN        Shed     700   \n",
       "17         Lvl    AllPub  ...        0    NaN    NaN        Shed     500   \n",
       "18         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "19         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "\n",
       "   MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0       2   2008        WD         Normal     208500  \n",
       "1       5   2007        WD         Normal     181500  \n",
       "2       9   2008        WD         Normal     223500  \n",
       "3       2   2006        WD        Abnorml     140000  \n",
       "4      12   2008        WD         Normal     250000  \n",
       "5      10   2009        WD         Normal     143000  \n",
       "6       8   2007        WD         Normal     307000  \n",
       "7      11   2009        WD         Normal     200000  \n",
       "8       4   2008        WD        Abnorml     129900  \n",
       "9       1   2008        WD         Normal     118000  \n",
       "10      2   2008        WD         Normal     129500  \n",
       "11      7   2006       New        Partial     345000  \n",
       "12      9   2008        WD         Normal     144000  \n",
       "13      8   2007       New        Partial     279500  \n",
       "14      5   2008        WD         Normal     157000  \n",
       "15      7   2007        WD         Normal     132000  \n",
       "16      3   2010        WD         Normal     149000  \n",
       "17     10   2006        WD         Normal      90000  \n",
       "18      6   2008        WD         Normal     159000  \n",
       "19      5   2009       COD        Abnorml     139000  \n",
       "\n",
       "[20 rows x 81 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../houseprice.csv')\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a5f8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['FireplaceQu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ddc7c24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['PoolQC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "553e4d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['Fence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1e2ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['MiscFeature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f0897df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['MSZoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b39d240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data ['Alley']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86b8e3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "1455  1456          60         62.0     7917   Pave      Reg         Lvl   \n",
       "1456  1457          20         85.0    13175   Pave      Reg         Lvl   \n",
       "1457  1458          70         66.0     9042   Pave      Reg         Lvl   \n",
       "1458  1459          20         68.0     9717   Pave      Reg         Lvl   \n",
       "1459  1460          20         75.0     9937   Pave      Reg         Lvl   \n",
       "\n",
       "     Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "1455    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1456    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1457    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1458    AllPub    Inside       Gtl  ...           112         0           0   \n",
       "1459    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "\n",
       "     PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "1455        0       0       8    2007        WD         Normal    175000  \n",
       "1456        0       0       2    2010        WD         Normal    210000  \n",
       "1457        0    2500       5    2010        WD         Normal    266500  \n",
       "1458        0       0       4    2010        WD         Normal    142125  \n",
       "1459        0       0       6    2008        WD         Normal    147500  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80a5fba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 73), (438, 73))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data.drop(labels = ['SalePrice', 'Id'], axis = 1),\n",
    "                                                   data.SalePrice,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=0)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d50dc08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 0.1773972602739726\n",
      "MasVnrType 0.005479452054794521\n",
      "MasVnrArea 0.005479452054794521\n",
      "BsmtQual 0.025342465753424658\n",
      "BsmtCond 0.025342465753424658\n",
      "BsmtExposure 0.026027397260273973\n",
      "BsmtFinType1 0.025342465753424658\n",
      "BsmtFinType2 0.026027397260273973\n",
      "Electrical 0.0006849315068493151\n",
      "GarageType 0.05547945205479452\n",
      "GarageYrBlt 0.05547945205479452\n",
      "GarageFinish 0.05547945205479452\n",
      "GarageQual 0.05547945205479452\n",
      "GarageCond 0.05547945205479452\n"
     ]
    }
   ],
   "source": [
    "for var in data.columns:\n",
    "    if data[var].isnull().sum() > 0:\n",
    "        print(var, data[var].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a15b8418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2887</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>ClearCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>20</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7207</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>50</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9060</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>30</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>60</td>\n",
       "      <td>82.0</td>\n",
       "      <td>9430</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>...</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>90</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8930</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3196</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Blmngtn</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>60</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR2</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea Street LotShape LandContour Utilities  \\\n",
       "64            60          NaN     9375   Pave      Reg         Lvl    AllPub   \n",
       "682          120          NaN     2887   Pave      Reg         HLS    AllPub   \n",
       "960           20         50.0     7207   Pave      IR1         Lvl    AllPub   \n",
       "1384          50         60.0     9060   Pave      Reg         Lvl    AllPub   \n",
       "1100          30         60.0     8400   Pave      Reg         Bnk    AllPub   \n",
       "...          ...          ...      ...    ...      ...         ...       ...   \n",
       "763           60         82.0     9430   Pave      Reg         Lvl    AllPub   \n",
       "835           20         60.0     9600   Pave      Reg         Lvl    AllPub   \n",
       "1216          90         68.0     8930   Pave      Reg         Lvl    AllPub   \n",
       "559          120          NaN     3196   Pave      Reg         Lvl    AllPub   \n",
       "684           60         58.0    16770   Pave      IR2         Lvl    AllPub   \n",
       "\n",
       "     LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch  \\\n",
       "64      Inside       Gtl      CollgCr  ...          36             0   \n",
       "682     Inside       Gtl      ClearCr  ...           0             0   \n",
       "960     Inside       Gtl      BrkSide  ...           0             0   \n",
       "1384    Inside       Gtl      Edwards  ...           0             0   \n",
       "1100    Inside       Gtl        SWISU  ...           0             0   \n",
       "...        ...       ...          ...  ...         ...           ...   \n",
       "763     Inside       Gtl      NoRidge  ...         128             0   \n",
       "835     Inside       Gtl       Sawyer  ...           0             0   \n",
       "1216    Inside       Gtl       Sawyer  ...           0             0   \n",
       "559     Inside       Gtl      Blmngtn  ...          20             0   \n",
       "684    CulDSac       Gtl      NoRidge  ...          81             0   \n",
       "\n",
       "     3SsnPorch ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType  \\\n",
       "64           0           0         0        0       2    2009       WD   \n",
       "682          0           0         0        0      11    2008       WD   \n",
       "960          0           0         0        0       2    2010       WD   \n",
       "1384         0           0         0        0      10    2009       WD   \n",
       "1100         0           0         0        0       1    2009       WD   \n",
       "...        ...         ...       ...      ...     ...     ...      ...   \n",
       "763          0         180         0        0       7    2009       WD   \n",
       "835          0           0         0        0       2    2010       WD   \n",
       "1216         0           0         0        0       4    2010       WD   \n",
       "559          0           0         0        0      10    2006       WD   \n",
       "684          0           0         0        0       6    2010       WD   \n",
       "\n",
       "     SaleCondition  \n",
       "64          Normal  \n",
       "682         Normal  \n",
       "960         Normal  \n",
       "1384        Normal  \n",
       "1100        Normal  \n",
       "...            ...  \n",
       "763         Normal  \n",
       "835         Normal  \n",
       "1216        Normal  \n",
       "559         Normal  \n",
       "684         Normal  \n",
       "\n",
       "[1022 rows x 73 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8050d7b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32668</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Alloca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>50</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9490</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7015</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>60</td>\n",
       "      <td>83.0</td>\n",
       "      <td>10005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>ClearCr</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>160</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1680</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrDale</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Family</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>20</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39104</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Low</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Sev</td>\n",
       "      <td>ClearCr</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>20</td>\n",
       "      <td>73.0</td>\n",
       "      <td>9855</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2009</td>\n",
       "      <td>COD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>20</td>\n",
       "      <td>91.0</td>\n",
       "      <td>10437</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>20</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9808</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>20</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12919</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass  LotFrontage  LotArea Street LotShape LandContour Utilities  \\\n",
       "529           20          NaN    32668   Pave      IR1         Lvl    AllPub   \n",
       "491           50         79.0     9490   Pave      Reg         Lvl    AllPub   \n",
       "459           50          NaN     7015   Pave      IR1         Bnk    AllPub   \n",
       "279           60         83.0    10005   Pave      Reg         Lvl    AllPub   \n",
       "655          160         21.0     1680   Pave      Reg         Lvl    AllPub   \n",
       "...          ...          ...      ...    ...      ...         ...       ...   \n",
       "271           20         73.0    39104   Pave      IR1         Low    AllPub   \n",
       "445           20         73.0     9855   Pave      Reg         Lvl    AllPub   \n",
       "654           20         91.0    10437   Pave      IR1         Lvl    AllPub   \n",
       "1280          20         67.0     9808   Pave      IR1         Lvl    AllPub   \n",
       "898           20        100.0    12919   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "     LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch  \\\n",
       "529    CulDSac       Gtl      Crawfor  ...           0           200   \n",
       "491     Inside       Gtl        NAmes  ...           0            32   \n",
       "459     Corner       Gtl      BrkSide  ...           0           248   \n",
       "279     Inside       Gtl      ClearCr  ...         117             0   \n",
       "655     Inside       Gtl       BrDale  ...           0             0   \n",
       "...        ...       ...          ...  ...         ...           ...   \n",
       "271    CulDSac       Sev      ClearCr  ...           0             0   \n",
       "445     Corner       Gtl      Edwards  ...           0             0   \n",
       "654     Inside       Gtl      NoRidge  ...          46             0   \n",
       "1280    Inside       Gtl      CollgCr  ...          72             0   \n",
       "898     Inside       Gtl      NridgHt  ...          67             0   \n",
       "\n",
       "     3SsnPorch ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType  \\\n",
       "529          0           0         0        0       3    2007       WD   \n",
       "491          0           0         0        0       8    2006       WD   \n",
       "459          0           0         0        0       7    2009       WD   \n",
       "279          0           0         0        0       3    2008       WD   \n",
       "655          0           0         0        0       3    2010       WD   \n",
       "...        ...         ...       ...      ...     ...     ...      ...   \n",
       "271          0           0         0        0       4    2008       WD   \n",
       "445          0           0         0        0      11    2009      COD   \n",
       "654          0           0         0        0       8    2008       WD   \n",
       "1280         0           0         0        0       3    2009       WD   \n",
       "898          0           0         0        0       3    2010      New   \n",
       "\n",
       "     SaleCondition  \n",
       "529         Alloca  \n",
       "491         Normal  \n",
       "459         Normal  \n",
       "279         Normal  \n",
       "655         Family  \n",
       "...            ...  \n",
       "271         Normal  \n",
       "445         Normal  \n",
       "654         Normal  \n",
       "1280        Normal  \n",
       "898        Partial  \n",
       "\n",
       "[438 rows x 73 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b22b1286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 0.18493150684931506\n",
      "MasVnrType 0.004892367906066536\n",
      "MasVnrArea 0.004892367906066536\n",
      "BsmtQual 0.023483365949119372\n",
      "BsmtCond 0.023483365949119372\n",
      "BsmtExposure 0.023483365949119372\n",
      "BsmtFinType1 0.023483365949119372\n",
      "BsmtFinType2 0.02446183953033268\n",
      "Electrical 0.0009784735812133072\n",
      "GarageType 0.05283757338551859\n",
      "GarageYrBlt 0.05283757338551859\n",
      "GarageFinish 0.05283757338551859\n",
      "GarageQual 0.05283757338551859\n",
      "GarageCond 0.05283757338551859\n"
     ]
    }
   ],
   "source": [
    "for var in x_train.columns:\n",
    "    if x_train[var].isnull().sum() > 0:\n",
    "        print(var, x_train[var].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb45197c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotFrontage 0.1598173515981735\n",
      "MasVnrType 0.00684931506849315\n",
      "MasVnrArea 0.00684931506849315\n",
      "BsmtQual 0.02968036529680365\n",
      "BsmtCond 0.02968036529680365\n",
      "BsmtExposure 0.0319634703196347\n",
      "BsmtFinType1 0.02968036529680365\n",
      "BsmtFinType2 0.02968036529680365\n",
      "GarageType 0.06164383561643835\n",
      "GarageYrBlt 0.06164383561643835\n",
      "GarageFinish 0.06164383561643835\n",
      "GarageQual 0.06164383561643835\n",
      "GarageCond 0.06164383561643835\n"
     ]
    }
   ],
   "source": [
    "for var in x_test.columns:\n",
    "    if x_test[var].isnull().sum() > 0:\n",
    "        print(var, x_test[var].isnull().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f64f5d11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass' 'LotFrontage' 'LotArea' 'OverallQual' 'OverallCond'\n",
      " 'YearBuilt' 'YearRemodAdd' 'MasVnrArea' 'BsmtFinSF1' 'BsmtFinSF2'\n",
      " 'BsmtUnfSF' 'TotalBsmtSF' '1stFlrSF' '2ndFlrSF' 'LowQualFinSF'\n",
      " 'GrLivArea' 'BsmtFullBath' 'BsmtHalfBath' 'FullBath' 'HalfBath'\n",
      " 'BedroomAbvGr' 'KitchenAbvGr' 'TotRmsAbvGrd' 'Fireplaces' 'GarageYrBlt'\n",
      " 'GarageCars' 'GarageArea' 'WoodDeckSF' 'OpenPorchSF' 'EnclosedPorch'\n",
      " '3SsnPorch' 'ScreenPorch' 'PoolArea' 'MiscVal' 'MoSold' 'YrSold']\n"
     ]
    }
   ],
   "source": [
    "print(x_train.select_dtypes(include = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "707042db",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_train = x_train.select_dtypes(include = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "239ff175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
       "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
       "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold'], dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95c03954",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Street' 'LotShape' 'LandContour' 'Utilities' 'LotConfig' 'LandSlope'\n",
      " 'Neighborhood' 'Condition1' 'Condition2' 'BldgType' 'HouseStyle'\n",
      " 'RoofStyle' 'RoofMatl' 'Exterior1st' 'Exterior2nd' 'MasVnrType'\n",
      " 'ExterQual' 'ExterCond' 'Foundation' 'BsmtQual' 'BsmtCond' 'BsmtExposure'\n",
      " 'BsmtFinType1' 'BsmtFinType2' 'Heating' 'HeatingQC' 'CentralAir'\n",
      " 'Electrical' 'KitchenQual' 'Functional' 'GarageType' 'GarageFinish'\n",
      " 'GarageQual' 'GarageCond' 'PavedDrive' 'SaleType' 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(x_train.select_dtypes(include = ['object']).columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49bb4e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_train = x_train.select_dtypes(include = ['object']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8d2fcf69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
       "       'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure',\n",
       "       'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
       "       'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'SaleType', 'SaleCondition'], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8e16e09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019226</td>\n",
       "      <td>-0.033335</td>\n",
       "      <td>-0.005364</td>\n",
       "      <td>-0.028771</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.005130</td>\n",
       "      <td>-0.011680</td>\n",
       "      <td>-0.035507</td>\n",
       "      <td>-0.013038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043239</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>-0.006758</td>\n",
       "      <td>-0.036706</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>0.055555</td>\n",
       "      <td>-0.043383</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.018546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSSubClass</th>\n",
       "      <td>0.019226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.314265</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>0.108065</td>\n",
       "      <td>-0.071770</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>-0.107629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>-0.035830</td>\n",
       "      <td>-0.021673</td>\n",
       "      <td>0.033250</td>\n",
       "      <td>-0.032840</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>-0.027401</td>\n",
       "      <td>0.007192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotFrontage</th>\n",
       "      <td>-0.033335</td>\n",
       "      <td>-0.314265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649633</td>\n",
       "      <td>0.254952</td>\n",
       "      <td>-0.083242</td>\n",
       "      <td>0.194510</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>0.258906</td>\n",
       "      <td>0.154014</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109288</td>\n",
       "      <td>0.178073</td>\n",
       "      <td>-0.095811</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>0.084534</td>\n",
       "      <td>0.024198</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.409076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LotArea</th>\n",
       "      <td>-0.005364</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>0.649633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.233303</td>\n",
       "      <td>-0.046912</td>\n",
       "      <td>0.103385</td>\n",
       "      <td>0.075158</td>\n",
       "      <td>0.177539</td>\n",
       "      <td>0.171995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184285</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>-0.066563</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>0.092316</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.059297</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>0.456461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallQual</th>\n",
       "      <td>-0.028771</td>\n",
       "      <td>0.108065</td>\n",
       "      <td>0.254952</td>\n",
       "      <td>0.233303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.177521</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>0.557723</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.132957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259439</td>\n",
       "      <td>0.435046</td>\n",
       "      <td>-0.162434</td>\n",
       "      <td>0.032903</td>\n",
       "      <td>0.046335</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>-0.088019</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>0.809829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallCond</th>\n",
       "      <td>0.003622</td>\n",
       "      <td>-0.071770</td>\n",
       "      <td>-0.083242</td>\n",
       "      <td>-0.046912</td>\n",
       "      <td>-0.177521</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.416964</td>\n",
       "      <td>-0.041464</td>\n",
       "      <td>-0.179187</td>\n",
       "      <td>-0.011087</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042662</td>\n",
       "      <td>-0.133284</td>\n",
       "      <td>0.109749</td>\n",
       "      <td>0.032384</td>\n",
       "      <td>0.074728</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>0.086625</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>-0.129325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearBuilt</th>\n",
       "      <td>-0.005130</td>\n",
       "      <td>0.035848</td>\n",
       "      <td>0.194510</td>\n",
       "      <td>0.103385</td>\n",
       "      <td>0.647392</td>\n",
       "      <td>-0.416964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.684388</td>\n",
       "      <td>0.402349</td>\n",
       "      <td>0.189645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>0.392691</td>\n",
       "      <td>-0.408622</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>-0.073119</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>-0.091786</td>\n",
       "      <td>0.018621</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.652682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <td>-0.011680</td>\n",
       "      <td>0.006802</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>0.075158</td>\n",
       "      <td>0.557723</td>\n",
       "      <td>-0.041464</td>\n",
       "      <td>0.684388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.234333</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230241</td>\n",
       "      <td>0.353325</td>\n",
       "      <td>-0.235037</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>-0.045808</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.090868</td>\n",
       "      <td>0.021081</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.571159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrArea</th>\n",
       "      <td>-0.035507</td>\n",
       "      <td>0.025035</td>\n",
       "      <td>0.258906</td>\n",
       "      <td>0.177539</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>-0.179187</td>\n",
       "      <td>0.402349</td>\n",
       "      <td>0.234333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173736</td>\n",
       "      <td>0.208681</td>\n",
       "      <td>-0.179589</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>-0.050279</td>\n",
       "      <td>0.017732</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.421309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <td>-0.013038</td>\n",
       "      <td>-0.107629</td>\n",
       "      <td>0.154014</td>\n",
       "      <td>0.171995</td>\n",
       "      <td>0.132957</td>\n",
       "      <td>-0.011087</td>\n",
       "      <td>0.189645</td>\n",
       "      <td>0.063353</td>\n",
       "      <td>0.241565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179359</td>\n",
       "      <td>0.081420</td>\n",
       "      <td>-0.148339</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>0.057586</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>-0.016405</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>0.301871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <td>-0.006736</td>\n",
       "      <td>-0.083871</td>\n",
       "      <td>0.052516</td>\n",
       "      <td>0.072019</td>\n",
       "      <td>-0.117560</td>\n",
       "      <td>0.102471</td>\n",
       "      <td>-0.111692</td>\n",
       "      <td>-0.126086</td>\n",
       "      <td>-0.061342</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069343</td>\n",
       "      <td>-0.068991</td>\n",
       "      <td>0.041524</td>\n",
       "      <td>-0.016079</td>\n",
       "      <td>0.058716</td>\n",
       "      <td>0.068076</td>\n",
       "      <td>0.030363</td>\n",
       "      <td>-0.025808</td>\n",
       "      <td>0.026054</td>\n",
       "      <td>-0.038806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <td>-0.009509</td>\n",
       "      <td>-0.117603</td>\n",
       "      <td>0.119436</td>\n",
       "      <td>0.077830</td>\n",
       "      <td>0.272939</td>\n",
       "      <td>-0.128270</td>\n",
       "      <td>0.139014</td>\n",
       "      <td>0.176921</td>\n",
       "      <td>0.075561</td>\n",
       "      <td>-0.573638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034866</td>\n",
       "      <td>0.156127</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>-0.012447</td>\n",
       "      <td>-0.036809</td>\n",
       "      <td>-0.044460</td>\n",
       "      <td>0.037116</td>\n",
       "      <td>-0.038552</td>\n",
       "      <td>0.185197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <td>-0.033187</td>\n",
       "      <td>-0.318897</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.366197</td>\n",
       "      <td>0.459915</td>\n",
       "      <td>-0.217375</td>\n",
       "      <td>0.427187</td>\n",
       "      <td>0.299042</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.410413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231045</td>\n",
       "      <td>0.270321</td>\n",
       "      <td>-0.171538</td>\n",
       "      <td>0.049173</td>\n",
       "      <td>0.088690</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>-0.061180</td>\n",
       "      <td>0.030340</td>\n",
       "      <td>-0.016530</td>\n",
       "      <td>0.602725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1stFlrSF</th>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.278318</td>\n",
       "      <td>0.427678</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.408730</td>\n",
       "      <td>-0.166686</td>\n",
       "      <td>0.293363</td>\n",
       "      <td>0.240265</td>\n",
       "      <td>0.352351</td>\n",
       "      <td>0.323478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218999</td>\n",
       "      <td>0.234713</td>\n",
       "      <td>-0.129189</td>\n",
       "      <td>0.060195</td>\n",
       "      <td>0.107512</td>\n",
       "      <td>0.070557</td>\n",
       "      <td>-0.033219</td>\n",
       "      <td>0.053828</td>\n",
       "      <td>-0.022411</td>\n",
       "      <td>0.575408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <td>0.009455</td>\n",
       "      <td>0.487749</td>\n",
       "      <td>0.055111</td>\n",
       "      <td>0.119356</td>\n",
       "      <td>0.289561</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>0.073049</td>\n",
       "      <td>0.063162</td>\n",
       "      <td>-0.191236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071047</td>\n",
       "      <td>0.225121</td>\n",
       "      <td>0.045793</td>\n",
       "      <td>-0.022861</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.061376</td>\n",
       "      <td>-0.005313</td>\n",
       "      <td>0.043437</td>\n",
       "      <td>-0.021784</td>\n",
       "      <td>0.293598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <td>-0.028463</td>\n",
       "      <td>0.075794</td>\n",
       "      <td>-0.030230</td>\n",
       "      <td>-0.020255</td>\n",
       "      <td>-0.034029</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>-0.145936</td>\n",
       "      <td>-0.064542</td>\n",
       "      <td>-0.106994</td>\n",
       "      <td>-0.079054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042103</td>\n",
       "      <td>0.010320</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>0.022432</td>\n",
       "      <td>-0.018578</td>\n",
       "      <td>0.065675</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>-0.003645</td>\n",
       "      <td>-0.035395</td>\n",
       "      <td>-0.067719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrLivArea</th>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.203576</td>\n",
       "      <td>0.375844</td>\n",
       "      <td>0.449040</td>\n",
       "      <td>0.603262</td>\n",
       "      <td>-0.153720</td>\n",
       "      <td>0.288493</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.057471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227158</td>\n",
       "      <td>0.398312</td>\n",
       "      <td>-0.049057</td>\n",
       "      <td>0.033912</td>\n",
       "      <td>0.085630</td>\n",
       "      <td>0.068298</td>\n",
       "      <td>-0.048969</td>\n",
       "      <td>0.080705</td>\n",
       "      <td>-0.026256</td>\n",
       "      <td>0.731310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <td>0.004662</td>\n",
       "      <td>-0.042017</td>\n",
       "      <td>0.085990</td>\n",
       "      <td>0.095609</td>\n",
       "      <td>0.098034</td>\n",
       "      <td>-0.052676</td>\n",
       "      <td>0.162080</td>\n",
       "      <td>0.099904</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.674175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169187</td>\n",
       "      <td>0.085672</td>\n",
       "      <td>-0.073447</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.030253</td>\n",
       "      <td>0.069112</td>\n",
       "      <td>-0.006701</td>\n",
       "      <td>-0.026924</td>\n",
       "      <td>0.062829</td>\n",
       "      <td>0.225125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <td>-0.021475</td>\n",
       "      <td>0.002480</td>\n",
       "      <td>-0.003854</td>\n",
       "      <td>0.045970</td>\n",
       "      <td>-0.050598</td>\n",
       "      <td>0.116015</td>\n",
       "      <td>-0.066313</td>\n",
       "      <td>-0.031495</td>\n",
       "      <td>0.032870</td>\n",
       "      <td>0.090712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049499</td>\n",
       "      <td>-0.040500</td>\n",
       "      <td>-0.036800</td>\n",
       "      <td>0.061530</td>\n",
       "      <td>0.037936</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>0.032481</td>\n",
       "      <td>0.036662</td>\n",
       "      <td>-0.040726</td>\n",
       "      <td>-0.012189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullBath</th>\n",
       "      <td>0.007269</td>\n",
       "      <td>0.194912</td>\n",
       "      <td>0.220234</td>\n",
       "      <td>0.235377</td>\n",
       "      <td>0.576372</td>\n",
       "      <td>-0.262400</td>\n",
       "      <td>0.537420</td>\n",
       "      <td>0.431390</td>\n",
       "      <td>0.290366</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226374</td>\n",
       "      <td>0.370152</td>\n",
       "      <td>-0.159420</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>-0.037236</td>\n",
       "      <td>0.042212</td>\n",
       "      <td>-0.048728</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>-0.012144</td>\n",
       "      <td>0.635957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HalfBath</th>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.282632</td>\n",
       "      <td>0.096777</td>\n",
       "      <td>0.142658</td>\n",
       "      <td>0.298455</td>\n",
       "      <td>-0.071342</td>\n",
       "      <td>0.244901</td>\n",
       "      <td>0.151562</td>\n",
       "      <td>0.168776</td>\n",
       "      <td>-0.013907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108268</td>\n",
       "      <td>0.267980</td>\n",
       "      <td>-0.127763</td>\n",
       "      <td>-0.000677</td>\n",
       "      <td>0.059158</td>\n",
       "      <td>0.027421</td>\n",
       "      <td>-0.032966</td>\n",
       "      <td>-0.004893</td>\n",
       "      <td>-0.011280</td>\n",
       "      <td>0.343008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <td>0.041650</td>\n",
       "      <td>0.068763</td>\n",
       "      <td>0.327679</td>\n",
       "      <td>0.337788</td>\n",
       "      <td>0.121517</td>\n",
       "      <td>-0.003713</td>\n",
       "      <td>-0.035257</td>\n",
       "      <td>-0.054371</td>\n",
       "      <td>0.113137</td>\n",
       "      <td>-0.084164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055579</td>\n",
       "      <td>0.099832</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>-0.018686</td>\n",
       "      <td>0.033808</td>\n",
       "      <td>0.071734</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.050677</td>\n",
       "      <td>-0.028372</td>\n",
       "      <td>0.234907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.277162</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>-0.022752</td>\n",
       "      <td>-0.192439</td>\n",
       "      <td>-0.099754</td>\n",
       "      <td>-0.155604</td>\n",
       "      <td>-0.154208</td>\n",
       "      <td>-0.049387</td>\n",
       "      <td>-0.106369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098364</td>\n",
       "      <td>-0.112484</td>\n",
       "      <td>0.035181</td>\n",
       "      <td>-0.027730</td>\n",
       "      <td>-0.051764</td>\n",
       "      <td>-0.014889</td>\n",
       "      <td>0.029948</td>\n",
       "      <td>0.027611</td>\n",
       "      <td>0.027165</td>\n",
       "      <td>-0.164826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <td>0.025888</td>\n",
       "      <td>0.165825</td>\n",
       "      <td>0.365999</td>\n",
       "      <td>0.405924</td>\n",
       "      <td>0.427806</td>\n",
       "      <td>-0.104919</td>\n",
       "      <td>0.176820</td>\n",
       "      <td>0.198243</td>\n",
       "      <td>0.263912</td>\n",
       "      <td>-0.050062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164980</td>\n",
       "      <td>0.285002</td>\n",
       "      <td>-0.028734</td>\n",
       "      <td>-0.002640</td>\n",
       "      <td>0.032286</td>\n",
       "      <td>0.059386</td>\n",
       "      <td>-0.021463</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>-0.036894</td>\n",
       "      <td>0.532586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fireplaces</th>\n",
       "      <td>-0.013644</td>\n",
       "      <td>0.019480</td>\n",
       "      <td>0.245315</td>\n",
       "      <td>0.350198</td>\n",
       "      <td>0.420626</td>\n",
       "      <td>-0.045383</td>\n",
       "      <td>0.174655</td>\n",
       "      <td>0.119270</td>\n",
       "      <td>0.255627</td>\n",
       "      <td>0.192264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213781</td>\n",
       "      <td>0.218727</td>\n",
       "      <td>-0.060932</td>\n",
       "      <td>0.035791</td>\n",
       "      <td>0.179235</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>0.043514</td>\n",
       "      <td>-0.034962</td>\n",
       "      <td>0.519247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.079268</td>\n",
       "      <td>0.115694</td>\n",
       "      <td>0.041796</td>\n",
       "      <td>0.618193</td>\n",
       "      <td>-0.379398</td>\n",
       "      <td>0.890546</td>\n",
       "      <td>0.722377</td>\n",
       "      <td>0.305964</td>\n",
       "      <td>0.078935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274373</td>\n",
       "      <td>0.394185</td>\n",
       "      <td>-0.317438</td>\n",
       "      <td>0.016935</td>\n",
       "      <td>-0.099749</td>\n",
       "      <td>-0.007330</td>\n",
       "      <td>-0.067091</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>-0.005770</td>\n",
       "      <td>0.593788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCars</th>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.024226</td>\n",
       "      <td>0.351756</td>\n",
       "      <td>0.340195</td>\n",
       "      <td>0.608756</td>\n",
       "      <td>-0.254763</td>\n",
       "      <td>0.601519</td>\n",
       "      <td>0.456245</td>\n",
       "      <td>0.401606</td>\n",
       "      <td>0.181381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255637</td>\n",
       "      <td>0.342701</td>\n",
       "      <td>-0.211429</td>\n",
       "      <td>0.035538</td>\n",
       "      <td>0.025837</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>-0.057536</td>\n",
       "      <td>0.040261</td>\n",
       "      <td>-0.039178</td>\n",
       "      <td>0.690711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageArea</th>\n",
       "      <td>0.006505</td>\n",
       "      <td>-0.047133</td>\n",
       "      <td>0.378052</td>\n",
       "      <td>0.367153</td>\n",
       "      <td>0.541552</td>\n",
       "      <td>-0.200718</td>\n",
       "      <td>0.528281</td>\n",
       "      <td>0.398267</td>\n",
       "      <td>0.364755</td>\n",
       "      <td>0.244161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247633</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>-0.177993</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.029071</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>-0.035918</td>\n",
       "      <td>0.032625</td>\n",
       "      <td>-0.021676</td>\n",
       "      <td>0.649379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <td>-0.043239</td>\n",
       "      <td>0.023370</td>\n",
       "      <td>0.109288</td>\n",
       "      <td>0.184285</td>\n",
       "      <td>0.259439</td>\n",
       "      <td>-0.042662</td>\n",
       "      <td>0.287729</td>\n",
       "      <td>0.230241</td>\n",
       "      <td>0.173736</td>\n",
       "      <td>0.179359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>-0.158257</td>\n",
       "      <td>-0.027760</td>\n",
       "      <td>-0.090229</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.353802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.178073</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.435046</td>\n",
       "      <td>-0.133284</td>\n",
       "      <td>0.392691</td>\n",
       "      <td>0.353325</td>\n",
       "      <td>0.208681</td>\n",
       "      <td>0.081420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.168911</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>-0.034794</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>-0.059019</td>\n",
       "      <td>0.477561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <td>-0.006758</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>-0.095811</td>\n",
       "      <td>-0.066563</td>\n",
       "      <td>-0.162434</td>\n",
       "      <td>0.109749</td>\n",
       "      <td>-0.408622</td>\n",
       "      <td>-0.235037</td>\n",
       "      <td>-0.179589</td>\n",
       "      <td>-0.148339</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.158257</td>\n",
       "      <td>-0.168911</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038790</td>\n",
       "      <td>-0.080716</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>-0.028538</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>-0.218394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3SsnPorch</th>\n",
       "      <td>-0.036706</td>\n",
       "      <td>-0.035830</td>\n",
       "      <td>0.063960</td>\n",
       "      <td>0.062282</td>\n",
       "      <td>0.032903</td>\n",
       "      <td>0.032384</td>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.046802</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027760</td>\n",
       "      <td>0.017123</td>\n",
       "      <td>-0.038790</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.037935</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.065440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScreenPorch</th>\n",
       "      <td>0.005962</td>\n",
       "      <td>-0.021673</td>\n",
       "      <td>0.043849</td>\n",
       "      <td>0.092316</td>\n",
       "      <td>0.046335</td>\n",
       "      <td>0.074728</td>\n",
       "      <td>-0.073119</td>\n",
       "      <td>-0.045808</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>0.071989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090229</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>-0.080716</td>\n",
       "      <td>-0.037935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>0.100070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoolArea</th>\n",
       "      <td>0.055555</td>\n",
       "      <td>0.033250</td>\n",
       "      <td>0.084534</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>-0.005605</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.004863</td>\n",
       "      <td>0.057586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>-0.008973</td>\n",
       "      <td>0.019035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041544</td>\n",
       "      <td>-0.023295</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>0.058453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscVal</th>\n",
       "      <td>-0.043383</td>\n",
       "      <td>-0.032840</td>\n",
       "      <td>0.024198</td>\n",
       "      <td>0.059297</td>\n",
       "      <td>-0.088019</td>\n",
       "      <td>0.086625</td>\n",
       "      <td>-0.091786</td>\n",
       "      <td>-0.090868</td>\n",
       "      <td>-0.050279</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>-0.034794</td>\n",
       "      <td>0.038746</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.041544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>-0.062727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MoSold</th>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.025758</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.018621</td>\n",
       "      <td>0.021081</td>\n",
       "      <td>0.017732</td>\n",
       "      <td>-0.016405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038058</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>-0.028538</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>-0.023295</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>0.069432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YrSold</th>\n",
       "      <td>0.001526</td>\n",
       "      <td>-0.027401</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>-0.025464</td>\n",
       "      <td>0.050214</td>\n",
       "      <td>-0.014100</td>\n",
       "      <td>0.045158</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.020793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>-0.059019</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.006790</td>\n",
       "      <td>0.023485</td>\n",
       "      <td>-0.058132</td>\n",
       "      <td>0.057210</td>\n",
       "      <td>-0.150937</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalePrice</th>\n",
       "      <td>-0.018546</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.409076</td>\n",
       "      <td>0.456461</td>\n",
       "      <td>0.809829</td>\n",
       "      <td>-0.129325</td>\n",
       "      <td>0.652682</td>\n",
       "      <td>0.571159</td>\n",
       "      <td>0.421309</td>\n",
       "      <td>0.301871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353802</td>\n",
       "      <td>0.477561</td>\n",
       "      <td>-0.218394</td>\n",
       "      <td>0.065440</td>\n",
       "      <td>0.100070</td>\n",
       "      <td>0.058453</td>\n",
       "      <td>-0.062727</td>\n",
       "      <td>0.069432</td>\n",
       "      <td>-0.029899</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Id  MSSubClass  LotFrontage   LotArea  OverallQual  \\\n",
       "Id             1.000000    0.019226    -0.033335 -0.005364    -0.028771   \n",
       "MSSubClass     0.019226    1.000000    -0.314265 -0.269570     0.108065   \n",
       "LotFrontage   -0.033335   -0.314265     1.000000  0.649633     0.254952   \n",
       "LotArea       -0.005364   -0.269570     0.649633  1.000000     0.233303   \n",
       "OverallQual   -0.028771    0.108065     0.254952  0.233303     1.000000   \n",
       "OverallCond    0.003622   -0.071770    -0.083242 -0.046912    -0.177521   \n",
       "YearBuilt     -0.005130    0.035848     0.194510  0.103385     0.647392   \n",
       "YearRemodAdd  -0.011680    0.006802     0.116772  0.075158     0.557723   \n",
       "MasVnrArea    -0.035507    0.025035     0.258906  0.177539     0.413500   \n",
       "BsmtFinSF1    -0.013038   -0.107629     0.154014  0.171995     0.132957   \n",
       "BsmtFinSF2    -0.006736   -0.083871     0.052516  0.072019    -0.117560   \n",
       "BsmtUnfSF     -0.009509   -0.117603     0.119436  0.077830     0.272939   \n",
       "TotalBsmtSF   -0.033187   -0.318897     0.386206  0.366197     0.459915   \n",
       "1stFlrSF      -0.000616   -0.278318     0.427678  0.443858     0.408730   \n",
       "2ndFlrSF       0.009455    0.487749     0.055111  0.119356     0.289561   \n",
       "LowQualFinSF  -0.028463    0.075794    -0.030230 -0.020255    -0.034029   \n",
       "GrLivArea      0.002812    0.203576     0.375844  0.449040     0.603262   \n",
       "BsmtFullBath   0.004662   -0.042017     0.085990  0.095609     0.098034   \n",
       "BsmtHalfBath  -0.021475    0.002480    -0.003854  0.045970    -0.050598   \n",
       "FullBath       0.007269    0.194912     0.220234  0.235377     0.576372   \n",
       "HalfBath       0.002564    0.282632     0.096777  0.142658     0.298455   \n",
       "BedroomAbvGr   0.041650    0.068763     0.327679  0.337788     0.121517   \n",
       "KitchenAbvGr   0.007574    0.277162     0.002231 -0.022752    -0.192439   \n",
       "TotRmsAbvGrd   0.025888    0.165825     0.365999  0.405924     0.427806   \n",
       "Fireplaces    -0.013644    0.019480     0.245315  0.350198     0.420626   \n",
       "GarageYrBlt   -0.000194    0.079268     0.115694  0.041796     0.618193   \n",
       "GarageCars     0.013301    0.024226     0.351756  0.340195     0.608756   \n",
       "GarageArea     0.006505   -0.047133     0.378052  0.367153     0.541552   \n",
       "WoodDeckSF    -0.043239    0.023370     0.109288  0.184285     0.259439   \n",
       "OpenPorchSF   -0.003225    0.031900     0.178073  0.176965     0.435046   \n",
       "EnclosedPorch -0.006758    0.011023    -0.095811 -0.066563    -0.162434   \n",
       "3SsnPorch     -0.036706   -0.035830     0.063960  0.062282     0.032903   \n",
       "ScreenPorch    0.005962   -0.021673     0.043849  0.092316     0.046335   \n",
       "PoolArea       0.055555    0.033250     0.084534  0.084460     0.056667   \n",
       "MiscVal       -0.043383   -0.032840     0.024198  0.059297    -0.088019   \n",
       "MoSold         0.019018    0.018403     0.025758  0.006423     0.061455   \n",
       "YrSold         0.001526   -0.027401     0.003461 -0.027473    -0.025464   \n",
       "SalePrice     -0.018546    0.007192     0.409076  0.456461     0.809829   \n",
       "\n",
       "               OverallCond  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  \\\n",
       "Id                0.003622  -0.005130     -0.011680   -0.035507   -0.013038   \n",
       "MSSubClass       -0.071770   0.035848      0.006802    0.025035   -0.107629   \n",
       "LotFrontage      -0.083242   0.194510      0.116772    0.258906    0.154014   \n",
       "LotArea          -0.046912   0.103385      0.075158    0.177539    0.171995   \n",
       "OverallQual      -0.177521   0.647392      0.557723    0.413500    0.132957   \n",
       "OverallCond       1.000000  -0.416964     -0.041464   -0.179187   -0.011087   \n",
       "YearBuilt        -0.416964   1.000000      0.684388    0.402349    0.189645   \n",
       "YearRemodAdd     -0.041464   0.684388      1.000000    0.234333    0.063353   \n",
       "MasVnrArea       -0.179187   0.402349      0.234333    1.000000    0.241565   \n",
       "BsmtFinSF1       -0.011087   0.189645      0.063353    0.241565    1.000000   \n",
       "BsmtFinSF2        0.102471  -0.111692     -0.126086   -0.061342    0.050398   \n",
       "BsmtUnfSF        -0.128270   0.139014      0.176921    0.075561   -0.573638   \n",
       "TotalBsmtSF      -0.217375   0.427187      0.299042    0.360104    0.410413   \n",
       "1stFlrSF         -0.166686   0.293363      0.240265    0.352351    0.323478   \n",
       "2ndFlrSF          0.001111   0.029716      0.073049    0.063162   -0.191236   \n",
       "LowQualFinSF      0.039556  -0.145936     -0.064542   -0.106994   -0.079054   \n",
       "GrLivArea        -0.153720   0.288493      0.282400    0.322678    0.057471   \n",
       "BsmtFullBath     -0.052676   0.162080      0.099904    0.121004    0.674175   \n",
       "BsmtHalfBath      0.116015  -0.066313     -0.031495    0.032870    0.090712   \n",
       "FullBath         -0.262400   0.537420      0.431390    0.290366    0.011986   \n",
       "HalfBath         -0.071342   0.244901      0.151562    0.168776   -0.013907   \n",
       "BedroomAbvGr     -0.003713  -0.035257     -0.054371    0.113137   -0.084164   \n",
       "KitchenAbvGr     -0.099754  -0.155604     -0.154208   -0.049387   -0.106369   \n",
       "TotRmsAbvGrd     -0.104919   0.176820      0.198243    0.263912   -0.050062   \n",
       "Fireplaces       -0.045383   0.174655      0.119270    0.255627    0.192264   \n",
       "GarageYrBlt      -0.379398   0.890546      0.722377    0.305964    0.078935   \n",
       "GarageCars       -0.254763   0.601519      0.456245    0.401606    0.181381   \n",
       "GarageArea       -0.200718   0.528281      0.398267    0.364755    0.244161   \n",
       "WoodDeckSF       -0.042662   0.287729      0.230241    0.173736    0.179359   \n",
       "OpenPorchSF      -0.133284   0.392691      0.353325    0.208681    0.081420   \n",
       "EnclosedPorch     0.109749  -0.408622     -0.235037   -0.179589   -0.148339   \n",
       "3SsnPorch         0.032384   0.022498      0.051694    0.040997    0.046802   \n",
       "ScreenPorch       0.074728  -0.073119     -0.045808    0.038171    0.071989   \n",
       "PoolArea         -0.005605   0.008986      0.002821    0.004863    0.057586   \n",
       "MiscVal           0.086625  -0.091786     -0.090868   -0.050279    0.005097   \n",
       "MoSold           -0.007203   0.018621      0.021081    0.017732   -0.016405   \n",
       "YrSold            0.050214  -0.014100      0.045158    0.000552    0.020793   \n",
       "SalePrice        -0.129325   0.652682      0.571159    0.421309    0.301871   \n",
       "\n",
       "               ...  WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  \\\n",
       "Id             ...   -0.043239    -0.003225      -0.006758  -0.036706   \n",
       "MSSubClass     ...    0.023370     0.031900       0.011023  -0.035830   \n",
       "LotFrontage    ...    0.109288     0.178073      -0.095811   0.063960   \n",
       "LotArea        ...    0.184285     0.176965      -0.066563   0.062282   \n",
       "OverallQual    ...    0.259439     0.435046      -0.162434   0.032903   \n",
       "OverallCond    ...   -0.042662    -0.133284       0.109749   0.032384   \n",
       "YearBuilt      ...    0.287729     0.392691      -0.408622   0.022498   \n",
       "YearRemodAdd   ...    0.230241     0.353325      -0.235037   0.051694   \n",
       "MasVnrArea     ...    0.173736     0.208681      -0.179589   0.040997   \n",
       "BsmtFinSF1     ...    0.179359     0.081420      -0.148339   0.046802   \n",
       "BsmtFinSF2     ...    0.069343    -0.068991       0.041524  -0.016079   \n",
       "BsmtUnfSF      ...   -0.034866     0.156127       0.044242   0.013418   \n",
       "TotalBsmtSF    ...    0.231045     0.270321      -0.171538   0.049173   \n",
       "1stFlrSF       ...    0.218999     0.234713      -0.129189   0.060195   \n",
       "2ndFlrSF       ...    0.071047     0.225121       0.045793  -0.022861   \n",
       "LowQualFinSF   ...   -0.042103     0.010320       0.047547   0.022432   \n",
       "GrLivArea      ...    0.227158     0.398312      -0.049057   0.033912   \n",
       "BsmtFullBath   ...    0.169187     0.085672      -0.073447   0.010204   \n",
       "BsmtHalfBath   ...    0.049499    -0.040500      -0.036800   0.061530   \n",
       "FullBath       ...    0.226374     0.370152      -0.159420   0.037323   \n",
       "HalfBath       ...    0.108268     0.267980      -0.127763  -0.000677   \n",
       "BedroomAbvGr   ...    0.055579     0.099832       0.002303  -0.018686   \n",
       "KitchenAbvGr   ...   -0.098364    -0.112484       0.035181  -0.027730   \n",
       "TotRmsAbvGrd   ...    0.164980     0.285002      -0.028734  -0.002640   \n",
       "Fireplaces     ...    0.213781     0.218727      -0.060932   0.035791   \n",
       "GarageYrBlt    ...    0.274373     0.394185      -0.317438   0.016935   \n",
       "GarageCars     ...    0.255637     0.342701      -0.211429   0.035538   \n",
       "GarageArea     ...    0.247633     0.338430      -0.177993   0.036300   \n",
       "WoodDeckSF     ...    1.000000     0.124200      -0.158257  -0.027760   \n",
       "OpenPorchSF    ...    0.124200     1.000000      -0.168911   0.017123   \n",
       "EnclosedPorch  ...   -0.158257    -0.168911       1.000000  -0.038790   \n",
       "3SsnPorch      ...   -0.027760     0.017123      -0.038790   1.000000   \n",
       "ScreenPorch    ...   -0.090229     0.006566      -0.080716  -0.037935   \n",
       "PoolArea       ...    0.050245     0.036890       0.003995  -0.008973   \n",
       "MiscVal        ...    0.017017    -0.034794       0.038746   0.004980   \n",
       "MoSold         ...    0.038058     0.066445      -0.028538   0.037039   \n",
       "YrSold         ...    0.022937    -0.059019       0.000519   0.006790   \n",
       "SalePrice      ...    0.353802     0.477561      -0.218394   0.065440   \n",
       "\n",
       "               ScreenPorch  PoolArea   MiscVal    MoSold    YrSold  SalePrice  \n",
       "Id                0.005962  0.055555 -0.043383  0.019018  0.001526  -0.018546  \n",
       "MSSubClass       -0.021673  0.033250 -0.032840  0.018403 -0.027401   0.007192  \n",
       "LotFrontage       0.043849  0.084534  0.024198  0.025758  0.003461   0.409076  \n",
       "LotArea           0.092316  0.084460  0.059297  0.006423 -0.027473   0.456461  \n",
       "OverallQual       0.046335  0.056667 -0.088019  0.061455 -0.025464   0.809829  \n",
       "OverallCond       0.074728 -0.005605  0.086625 -0.007203  0.050214  -0.129325  \n",
       "YearBuilt        -0.073119  0.008986 -0.091786  0.018621 -0.014100   0.652682  \n",
       "YearRemodAdd     -0.045808  0.002821 -0.090868  0.021081  0.045158   0.571159  \n",
       "MasVnrArea        0.038171  0.004863 -0.050279  0.017732  0.000552   0.421309  \n",
       "BsmtFinSF1        0.071989  0.057586  0.005097 -0.016405  0.020793   0.301871  \n",
       "BsmtFinSF2        0.058716  0.068076  0.030363 -0.025808  0.026054  -0.038806  \n",
       "BsmtUnfSF        -0.012447 -0.036809 -0.044460  0.037116 -0.038552   0.185197  \n",
       "TotalBsmtSF       0.088690  0.047067 -0.061180  0.030340 -0.016530   0.602725  \n",
       "1stFlrSF          0.107512  0.070557 -0.033219  0.053828 -0.022411   0.575408  \n",
       "2ndFlrSF          0.012173  0.061376 -0.005313  0.043437 -0.021784   0.293598  \n",
       "LowQualFinSF     -0.018578  0.065675  0.029123 -0.003645 -0.035395  -0.067719  \n",
       "GrLivArea         0.085630  0.068298 -0.048969  0.080705 -0.026256   0.731310  \n",
       "BsmtFullBath      0.030253  0.069112 -0.006701 -0.026924  0.062829   0.225125  \n",
       "BsmtHalfBath      0.037936  0.025957  0.032481  0.036662 -0.040726  -0.012189  \n",
       "FullBath         -0.037236  0.042212 -0.048728  0.066774 -0.012144   0.635957  \n",
       "HalfBath          0.059158  0.027421 -0.032966 -0.004893 -0.011280   0.343008  \n",
       "BedroomAbvGr      0.033808  0.071734  0.012503  0.050677 -0.028372   0.234907  \n",
       "KitchenAbvGr     -0.051764 -0.014889  0.029948  0.027611  0.027165  -0.164826  \n",
       "TotRmsAbvGrd      0.032286  0.059386 -0.021463  0.040138 -0.036894   0.532586  \n",
       "Fireplaces        0.179235  0.083876 -0.007546  0.043514 -0.034962   0.519247  \n",
       "GarageYrBlt      -0.099749 -0.007330 -0.067091  0.012337 -0.005770   0.593788  \n",
       "GarageCars        0.025837  0.021783 -0.057536  0.040261 -0.039178   0.690711  \n",
       "GarageArea        0.029071  0.042387 -0.035918  0.032625 -0.021676   0.649379  \n",
       "WoodDeckSF       -0.090229  0.050245  0.017017  0.038058  0.022937   0.353802  \n",
       "OpenPorchSF       0.006566  0.036890 -0.034794  0.066445 -0.059019   0.477561  \n",
       "EnclosedPorch    -0.080716  0.003995  0.038746 -0.028538  0.000519  -0.218394  \n",
       "3SsnPorch        -0.037935 -0.008973  0.004980  0.037039  0.006790   0.065440  \n",
       "ScreenPorch       1.000000  0.019035  0.015435  0.023643  0.023485   0.100070  \n",
       "PoolArea          0.019035  1.000000  0.041544 -0.023295 -0.058132   0.058453  \n",
       "MiscVal           0.015435  0.041544  1.000000  0.011075  0.057210  -0.062727  \n",
       "MoSold            0.023643 -0.023295  0.011075  1.000000 -0.150937   0.069432  \n",
       "YrSold            0.023485 -0.058132  0.057210 -0.150937  1.000000  -0.029899  \n",
       "SalePrice         0.100070  0.058453 -0.062727  0.069432 -0.029899   1.000000  \n",
       "\n",
       "[38 rows x 38 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr(method = \"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0a6d321c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x792 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrmat = x_train.corr(method = 'pearson')\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap = True)\n",
    "fig, ax =plt.subplots()\n",
    "fig.set_size_inches(11, 11)\n",
    "sns.heatmap(corrmat, cmap = cmap, annot = None, linewidths=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77a13927",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSSubClass :  15 labels\n",
      "LotFrontage :  102 labels\n",
      "LotArea :  790 labels\n",
      "Street :  2 labels\n",
      "LotShape :  4 labels\n",
      "LandContour :  4 labels\n",
      "Utilities :  2 labels\n",
      "LotConfig :  5 labels\n",
      "LandSlope :  3 labels\n",
      "Neighborhood :  25 labels\n",
      "Condition1 :  9 labels\n",
      "Condition2 :  5 labels\n",
      "BldgType :  5 labels\n",
      "HouseStyle :  8 labels\n",
      "OverallQual :  10 labels\n",
      "OverallCond :  9 labels\n",
      "YearBuilt :  107 labels\n",
      "YearRemodAdd :  61 labels\n",
      "RoofStyle :  6 labels\n",
      "RoofMatl :  6 labels\n",
      "Exterior1st :  15 labels\n",
      "Exterior2nd :  16 labels\n",
      "MasVnrType :  5 labels\n",
      "MasVnrArea :  262 labels\n",
      "ExterQual :  4 labels\n",
      "ExterCond :  5 labels\n",
      "Foundation :  6 labels\n",
      "BsmtQual :  5 labels\n",
      "BsmtCond :  5 labels\n",
      "BsmtExposure :  5 labels\n",
      "BsmtFinType1 :  7 labels\n",
      "BsmtFinSF1 :  503 labels\n",
      "BsmtFinType2 :  7 labels\n",
      "BsmtFinSF2 :  113 labels\n",
      "BsmtUnfSF :  627 labels\n",
      "TotalBsmtSF :  573 labels\n",
      "Heating :  6 labels\n",
      "HeatingQC :  5 labels\n",
      "CentralAir :  2 labels\n",
      "Electrical :  6 labels\n",
      "1stFlrSF :  617 labels\n",
      "2ndFlrSF :  326 labels\n",
      "LowQualFinSF :  18 labels\n",
      "GrLivArea :  670 labels\n",
      "BsmtFullBath :  4 labels\n",
      "BsmtHalfBath :  3 labels\n",
      "FullBath :  4 labels\n",
      "HalfBath :  3 labels\n",
      "BedroomAbvGr :  8 labels\n",
      "KitchenAbvGr :  4 labels\n",
      "KitchenQual :  4 labels\n",
      "TotRmsAbvGrd :  12 labels\n",
      "Functional :  6 labels\n",
      "Fireplaces :  4 labels\n",
      "GarageType :  7 labels\n",
      "GarageYrBlt :  95 labels\n",
      "GarageFinish :  4 labels\n",
      "GarageCars :  5 labels\n",
      "GarageArea :  376 labels\n",
      "GarageQual :  6 labels\n",
      "GarageCond :  6 labels\n",
      "PavedDrive :  3 labels\n",
      "WoodDeckSF :  225 labels\n",
      "OpenPorchSF :  173 labels\n",
      "EnclosedPorch :  103 labels\n",
      "3SsnPorch :  17 labels\n",
      "ScreenPorch :  62 labels\n",
      "PoolArea :  4 labels\n",
      "MiscVal :  21 labels\n",
      "MoSold :  12 labels\n",
      "YrSold :  5 labels\n",
      "SaleType :  9 labels\n",
      "SaleCondition :  6 labels\n"
     ]
    }
   ],
   "source": [
    "for col in x_train.columns:\n",
    "    print(col, ': ', len(x_train[col].unique()), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1143618b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 75 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   LotShape       1460 non-null   object \n",
      " 6   LandContour    1460 non-null   object \n",
      " 7   Utilities      1460 non-null   object \n",
      " 8   LotConfig      1460 non-null   object \n",
      " 9   LandSlope      1460 non-null   object \n",
      " 10  Neighborhood   1460 non-null   object \n",
      " 11  Condition1     1460 non-null   object \n",
      " 12  Condition2     1460 non-null   object \n",
      " 13  BldgType       1460 non-null   object \n",
      " 14  HouseStyle     1460 non-null   object \n",
      " 15  OverallQual    1460 non-null   int64  \n",
      " 16  OverallCond    1460 non-null   int64  \n",
      " 17  YearBuilt      1460 non-null   int64  \n",
      " 18  YearRemodAdd   1460 non-null   int64  \n",
      " 19  RoofStyle      1460 non-null   object \n",
      " 20  RoofMatl       1460 non-null   object \n",
      " 21  Exterior1st    1460 non-null   object \n",
      " 22  Exterior2nd    1460 non-null   object \n",
      " 23  MasVnrType     1452 non-null   object \n",
      " 24  MasVnrArea     1452 non-null   float64\n",
      " 25  ExterQual      1460 non-null   object \n",
      " 26  ExterCond      1460 non-null   object \n",
      " 27  Foundation     1460 non-null   object \n",
      " 28  BsmtQual       1423 non-null   object \n",
      " 29  BsmtCond       1423 non-null   object \n",
      " 30  BsmtExposure   1422 non-null   object \n",
      " 31  BsmtFinType1   1423 non-null   object \n",
      " 32  BsmtFinSF1     1460 non-null   int64  \n",
      " 33  BsmtFinType2   1422 non-null   object \n",
      " 34  BsmtFinSF2     1460 non-null   int64  \n",
      " 35  BsmtUnfSF      1460 non-null   int64  \n",
      " 36  TotalBsmtSF    1460 non-null   int64  \n",
      " 37  Heating        1460 non-null   object \n",
      " 38  HeatingQC      1460 non-null   object \n",
      " 39  CentralAir     1460 non-null   object \n",
      " 40  Electrical     1459 non-null   object \n",
      " 41  1stFlrSF       1460 non-null   int64  \n",
      " 42  2ndFlrSF       1460 non-null   int64  \n",
      " 43  LowQualFinSF   1460 non-null   int64  \n",
      " 44  GrLivArea      1460 non-null   int64  \n",
      " 45  BsmtFullBath   1460 non-null   int64  \n",
      " 46  BsmtHalfBath   1460 non-null   int64  \n",
      " 47  FullBath       1460 non-null   int64  \n",
      " 48  HalfBath       1460 non-null   int64  \n",
      " 49  BedroomAbvGr   1460 non-null   int64  \n",
      " 50  KitchenAbvGr   1460 non-null   int64  \n",
      " 51  KitchenQual    1460 non-null   object \n",
      " 52  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 53  Functional     1460 non-null   object \n",
      " 54  Fireplaces     1460 non-null   int64  \n",
      " 55  GarageType     1379 non-null   object \n",
      " 56  GarageYrBlt    1379 non-null   float64\n",
      " 57  GarageFinish   1379 non-null   object \n",
      " 58  GarageCars     1460 non-null   int64  \n",
      " 59  GarageArea     1460 non-null   int64  \n",
      " 60  GarageQual     1379 non-null   object \n",
      " 61  GarageCond     1379 non-null   object \n",
      " 62  PavedDrive     1460 non-null   object \n",
      " 63  WoodDeckSF     1460 non-null   int64  \n",
      " 64  OpenPorchSF    1460 non-null   int64  \n",
      " 65  EnclosedPorch  1460 non-null   int64  \n",
      " 66  3SsnPorch      1460 non-null   int64  \n",
      " 67  ScreenPorch    1460 non-null   int64  \n",
      " 68  PoolArea       1460 non-null   int64  \n",
      " 69  MiscVal        1460 non-null   int64  \n",
      " 70  MoSold         1460 non-null   int64  \n",
      " 71  YrSold         1460 non-null   int64  \n",
      " 72  SaleType       1460 non-null   object \n",
      " 73  SaleCondition  1460 non-null   object \n",
      " 74  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(37)\n",
      "memory usage: 855.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "efe1f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_vars = [var for var in x_train.columns if x_train[var].dtypes !='O'\n",
    "               and var != 'SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9d4541d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete = [var for var in x_train.columns if x_train[var].dtypes !='O'\n",
    "           and var !='SalePrice' and x_train[var].nunique() <20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0f43446",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list_1 = [var for var in numeric_vars if var not in discrete\n",
    "           and var not in ['Id','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78d00a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = num_list_1 + discrete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8107826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = [var for var in x_train.columns if x_train[var].dtype == 'O']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83f1716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_list = categorical_vars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4cec4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[cat_list] = x_train[cat_list].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1755f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test[cat_list] = x_test[cat_list].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "48d8f261",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy().reshape(-1,1)\n",
    "y_test = y_test.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f07510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "y_train = scaler.fit_transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7ed86390",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1)\n",
    "y_test = y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "70d0dcda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe_dtr = Pipeline([('imputer_num', MeanMedianImputer(imputation_method= 'median', variables=num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables=cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3)),\n",
    "                 ('discretiser', EqualFrequencyDiscretiser (q = 6, return_object = True, variables=num_list)),\n",
    "                 ('encoder', OrdinalEncoder(variables= cat_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998, missing_values ='raise')),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('DTR', DecisionTreeRegressor(random_state= 0))])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "be96b9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dtr_param_grid = [{\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
    "    'discretiser__q': [5, 6, 7],\n",
    "    'DTR__max_depth': [2, 3, 4, 5], \n",
    "    'DTR__criterion': ['squared_error', 'absolute_error', 'poisson', 'friedman_mse']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "99f5991f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_grid_search = GridSearchCV(estimator=pipe_dtr, param_grid = dtr_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "32c16309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "624 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "192 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "432 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 178, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.56756641 0.56756641        nan        nan\n",
      " 0.56756641 0.56756641        nan        nan 0.5663202  0.5663202\n",
      "        nan        nan 0.5663202  0.5663202         nan        nan\n",
      " 0.59261389 0.59261389        nan        nan 0.59261389 0.59261389\n",
      "        nan        nan 0.63523772 0.63523772        nan        nan\n",
      " 0.63925576 0.63925576        nan        nan 0.63028708 0.63028708\n",
      "        nan        nan 0.63279474 0.63279474        nan        nan\n",
      " 0.64528313 0.64528313        nan        nan 0.62211428 0.62211428\n",
      "        nan        nan 0.68756109 0.68756109        nan        nan\n",
      " 0.67026627 0.67026627        nan        nan 0.67603337 0.67606898\n",
      "        nan        nan 0.6662016  0.66623722        nan        nan\n",
      " 0.68665241 0.68665241        nan        nan 0.66402459 0.66402459\n",
      "        nan        nan 0.72189472 0.72189472        nan        nan\n",
      " 0.70854202 0.70854202        nan        nan 0.68152098 0.6816097\n",
      "        nan        nan 0.65856406 0.65865278        nan        nan\n",
      " 0.69173509 0.69246182        nan        nan 0.62775186 0.62775186\n",
      "        nan        nan 0.59118535 0.59118535        nan        nan\n",
      " 0.59118535 0.59118535        nan        nan 0.59076683 0.59076683\n",
      "        nan        nan 0.59076683 0.59076683        nan        nan\n",
      " 0.58899792 0.58899792        nan        nan 0.58899792 0.58899792\n",
      "        nan        nan 0.67239813 0.67239813        nan        nan\n",
      " 0.67670435 0.67670435        nan        nan 0.65952981 0.65952981\n",
      "        nan        nan 0.66383602 0.66383602        nan        nan\n",
      " 0.68399907 0.68399907        nan        nan 0.68399907 0.68399907\n",
      "        nan        nan 0.70257563 0.70257563        nan        nan\n",
      " 0.70779426 0.70779426        nan        nan 0.70061571 0.70061571\n",
      "        nan        nan 0.7022718  0.7022718         nan        nan\n",
      " 0.72305771 0.72305771        nan        nan 0.73401    0.73401\n",
      "        nan        nan 0.72839405 0.73010458        nan        nan\n",
      " 0.71781333 0.71781333        nan        nan 0.72502022 0.72259502\n",
      "        nan        nan 0.71954431 0.70614467        nan        nan\n",
      " 0.72208241 0.72208241        nan        nan 0.74166475 0.73833822\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.56756641 0.56756641        nan        nan\n",
      " 0.56756641 0.56756641        nan        nan 0.5663202  0.5663202\n",
      "        nan        nan 0.5663202  0.5663202         nan        nan\n",
      " 0.59261389 0.59261389        nan        nan 0.59261389 0.59261389\n",
      "        nan        nan 0.63523772 0.63523772        nan        nan\n",
      " 0.63925576 0.63925576        nan        nan 0.63028708 0.63028708\n",
      "        nan        nan 0.63279474 0.63279474        nan        nan\n",
      " 0.64528313 0.64528313        nan        nan 0.62211428 0.62211428\n",
      "        nan        nan 0.68756109 0.68756109        nan        nan\n",
      " 0.67026627 0.67026627        nan        nan 0.67603337 0.67606898\n",
      "        nan        nan 0.6662016  0.66623722        nan        nan\n",
      " 0.68665241 0.68665241        nan        nan 0.66402459 0.66402459\n",
      "        nan        nan 0.72189472 0.72189472        nan        nan\n",
      " 0.70882412 0.70882412        nan        nan 0.68152098 0.6816097\n",
      "        nan        nan 0.65856406 0.65865278        nan        nan\n",
      " 0.69173509 0.69246182        nan        nan 0.63509665 0.63509665]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'MiscVal',\n",
       "                                                                     'MSSubClass',\n",
       "                                                                     'Over...\n",
       "                                        DecisionTreeRegressor(random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'DTR__criterion': ['squared_error', 'absolute_error',\n",
       "                                             'poisson', 'friedman_mse'],\n",
       "                          'DTR__max_depth': [2, 3, 4, 5],\n",
       "                          'discretiser__q': [5, 6, 7],\n",
       "                          'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
       "                          'imputer_cat__imputation_method': ['frequent',\n",
       "                                                             'missing'],\n",
       "                          'imputer_num__imputation_method': ['mean',\n",
       "                                                             'median']}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3d2d39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor R2 score train set:0.8405925992844498\n",
      "Decision Tree Regressor R2 score train set:0.7266770860259311\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('Decision Tree Regressor', dtr_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('Decision Tree Regressor', dtr_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fe99b28a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DTR__criterion': 'absolute_error',\n",
       " 'DTR__max_depth': 5,\n",
       " 'discretiser__q': 7,\n",
       " 'encoder__encoding_method': 'arbitrary',\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'mean'}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dc9a4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([('imputer_num', MeanMedianImputer(imputation_method='mean', variables = num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables = cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3, variables = cat_list)),\n",
    "                 ('discretiser', EqualWidthDiscretiser(bins = 10, variables = num_list)),\n",
    "                 ('encoder', OrdinalEncoder(variables= cat_list)),\n",
    "                 ('scaler', SklearnTransformerWrapper(transformer= StandardScaler(), variables = num_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998, variables = num_list + cat_list)),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('KNN', KNeighborsRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b2070a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
    "    'discretiser__bins': [8, 10, 12, 14],\n",
    "    'KNN__weights': ['uniform', 'distance'], \n",
    "    'KNN__n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'KNN__metric': ['minkowski', 'euclidean'], \n",
    "    'KNN__leaf_size': [3, 4, 5, 7, 10, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "687bb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_search = GridSearchCV(estimator = pipe_knn, param_grid = knn_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3f269d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1920 fits failed out of a total of 19200.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1920 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.75393524 ...        nan 0.74050497 0.7402532 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(imputation_method='mean',\n",
       "                                                          variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'Mi...\n",
       "             param_grid={'KNN__leaf_size': [3, 4, 5, 7, 10, 30],\n",
       "                         'KNN__metric': ['minkowski', 'euclidean'],\n",
       "                         'KNN__n_neighbors': [3, 5, 7, 9, 11],\n",
       "                         'KNN__weights': ['uniform', 'distance'],\n",
       "                         'discretiser__bins': [8, 10, 12, 14],\n",
       "                         'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
       "                         'imputer_cat__imputation_method': ['frequent',\n",
       "                                                            'missing'],\n",
       "                         'imputer_num__imputation_method': ['mean', 'median']},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7b5fd933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN R2 score train set:0.9999999999999964\n",
      "KNN R2 score train set:0.7639761557957387\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('KNN', knn_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('KNN', knn_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "042d0464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN__leaf_size': 3,\n",
       " 'KNN__metric': 'minkowski',\n",
       " 'KNN__n_neighbors': 11,\n",
       " 'KNN__weights': 'distance',\n",
       " 'discretiser__bins': 10,\n",
       " 'encoder__encoding_method': 'ordered',\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'median'}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c664169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline([('imputer_num', MeanMedianImputer(imputation_method='mean', variables = num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables = cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3, variables = cat_list)),\n",
    "                 ('discretiser', EqualWidthDiscretiser(bins = 10, variables = num_list)),\n",
    "                 ('encoder', OrdinalEncoder(variables= cat_list)), \n",
    "                 ('scaler', SklearnTransformerWrapper(transformer= StandardScaler(), variables = num_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998, variables = num_list + cat_list)),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('LR', LinearRegression())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "421bbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_param_grid = [{\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'discretiser__bins': [8, 10, 12, 14],\n",
    "    'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
    "    'LR__fit_intercept': [True, False], \n",
    "    'LR__copy_X': [True, False], \n",
    "    'LR__n_jobs': [-1, None],\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "700b185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_search = GridSearchCV(estimator=pipe_lr, param_grid = lr_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "123da687",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "128 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "128 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.83199203 0.83199203        nan        nan\n",
      " 0.83211485 0.83211485        nan        nan 0.83183108 0.83151566\n",
      "        nan        nan 0.83407739 0.8342865         nan        nan\n",
      " 0.83429685 0.83475267        nan        nan 0.83718168 0.8373696\n",
      "        nan        nan 0.83809834 0.83791026        nan        nan\n",
      " 0.84382023 0.84220508        nan        nan 0.83199203 0.83199203\n",
      "        nan        nan 0.83211485 0.83211485        nan        nan\n",
      " 0.83183108 0.83185635        nan        nan 0.83407739 0.83414313\n",
      "        nan        nan 0.83429685 0.83475267        nan        nan\n",
      " 0.83718168 0.8373696         nan        nan 0.83809834 0.83791026\n",
      "        nan        nan 0.84382023 0.84220508        nan        nan\n",
      " 0.83527941 0.83527941        nan        nan 0.82962346 0.82962346\n",
      "        nan        nan 0.83444637 0.83449054        nan        nan\n",
      " 0.83192466 0.83203541        nan        nan 0.8367836  0.83723952\n",
      "        nan        nan 0.83493078 0.83507964        nan        nan\n",
      " 0.84116322 0.84101249        nan        nan 0.84227777 0.84070347\n",
      "        nan        nan 0.83527941 0.83527941        nan        nan\n",
      " 0.82962346 0.82962346        nan        nan 0.83412038 0.83416455\n",
      "        nan        nan 0.83192466 0.83203541        nan        nan\n",
      " 0.8367836  0.83723952        nan        nan 0.83493078 0.83507964\n",
      "        nan        nan 0.84116322 0.84101249        nan        nan\n",
      " 0.84227777 0.84070347        nan        nan 0.83199203 0.83199203\n",
      "        nan        nan 0.83211485 0.83211485        nan        nan\n",
      " 0.83183108 0.83185635        nan        nan 0.83407739 0.8342865\n",
      "        nan        nan 0.83429685 0.83475267        nan        nan\n",
      " 0.83718168 0.8373696         nan        nan 0.83809834 0.83791026\n",
      "        nan        nan 0.84382023 0.84220508        nan        nan\n",
      " 0.83199203 0.83199203        nan        nan 0.83211485 0.83211485\n",
      "        nan        nan 0.83183108 0.83151566        nan        nan\n",
      " 0.83422076 0.83414313        nan        nan 0.83429685 0.83475267\n",
      "        nan        nan 0.83718168 0.8373696         nan        nan\n",
      " 0.83809834 0.83791026        nan        nan 0.84382023 0.84220508\n",
      "        nan        nan 0.83527941 0.83527941        nan        nan\n",
      " 0.82962346 0.82962346        nan        nan 0.83412038 0.83449054\n",
      "        nan        nan 0.83192466 0.83203541        nan        nan\n",
      " 0.8367836  0.83723952        nan        nan 0.83493078 0.83507964\n",
      "        nan        nan 0.84116322 0.84101249        nan        nan\n",
      " 0.84227777 0.84070347        nan        nan 0.83527941 0.83527941\n",
      "        nan        nan 0.82962346 0.82962346        nan        nan\n",
      " 0.83444637 0.83449054        nan        nan 0.83177287 0.83203541\n",
      "        nan        nan 0.8367836  0.83723952        nan        nan\n",
      " 0.83493078 0.83507964        nan        nan 0.84116322 0.84101249\n",
      "        nan        nan 0.84227777 0.84070347]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(imputation_method='mean',\n",
       "                                                          variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'Mi...\n",
       "                                        SmartCorrelatedSelection(selection_method='variance')),\n",
       "                                       ('LR', LinearRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'LR__copy_X': [True, False],\n",
       "                          'LR__fit_intercept': [True, False],\n",
       "                          'LR__n_jobs': [-1, None],\n",
       "                          'discretiser__bins': [8, 10, 12, 14],\n",
       "                          'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
       "                          'imputer_cat__imputation_method': ['frequent',\n",
       "                                                             'missing'],\n",
       "                          'imputer_num__imputation_method': ['mean',\n",
       "                                                             'median']}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a92036aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression R2 score train set:0.8835461263970219\n",
      "Linear Regression R2 score train set:0.7842981256931201\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('Linear Regression', lr_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('Linear Regression', lr_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f6cd31fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR__copy_X': True,\n",
       " 'LR__fit_intercept': True,\n",
       " 'LR__n_jobs': -1,\n",
       " 'discretiser__bins': 14,\n",
       " 'encoder__encoding_method': 'arbitrary',\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'mean'}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "018dd1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lasso = Pipeline([('imputer_num', MeanMedianImputer(imputation_method='mean', variables = num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables = cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3, variables = cat_list)),\n",
    "                 ('discretiser', EqualWidthDiscretiser(bins = 10, variables = num_list)),\n",
    "                 ('encoder', OneHotEncoder()),\n",
    "                 ('scaler', SklearnTransformerWrapper(transformer= StandardScaler(), variables = num_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998)),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('Lasso', Lasso (random_state = 0))])\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d831435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_param_grid = [{\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'encoder__top_categories': [5, 7, 10, None],\n",
    "    'discretiser__bins': [8, 10, 12],\n",
    "    'Lasso__alpha': (1, 0),\n",
    "    'Lasso__max_iter': [10, 100, 1000]\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d3f8b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_grid_search = GridSearchCV(estimator=pipe_lasso, param_grid = lasso_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "af7c9668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 1440.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "144 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.10291818 0.10291818        nan        nan 0.10291818 0.10291818\n",
      "        nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.1835574  0.1835574\n",
      "        nan        nan 0.1835574  0.1835574         nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.32082301 0.32082301\n",
      "        nan        nan 0.32082301 0.32082301        nan        nan\n",
      " 0.32082301 0.32082301        nan        nan 0.32082301 0.32082301\n",
      "        nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.10291818 0.10291818        nan        nan 0.10291818 0.10291818\n",
      "        nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.1835574  0.1835574\n",
      "        nan        nan 0.1835574  0.1835574         nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.32083159 0.32083159\n",
      "        nan        nan 0.32083159 0.32083159        nan        nan\n",
      " 0.32083159 0.32083159        nan        nan 0.32083159 0.32083159\n",
      "        nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.10291818 0.10291818        nan        nan 0.10291818 0.10291818\n",
      "        nan        nan 0.10291818 0.10291818        nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.1835574  0.1835574\n",
      "        nan        nan 0.1835574  0.1835574         nan        nan\n",
      " 0.1835574  0.1835574         nan        nan 0.32083159 0.32083159\n",
      "        nan        nan 0.32083159 0.32083159        nan        nan\n",
      " 0.32083159 0.32083159        nan        nan 0.32083159 0.32083159\n",
      "        nan        nan 0.8142137  0.8142137         nan        nan\n",
      " 0.81414691 0.81414537        nan        nan 0.81282039 0.81283539\n",
      "        nan        nan 0.81365277 0.81365277        nan        nan\n",
      " 0.81729347 0.81718094        nan        nan 0.81598914 0.81594135\n",
      "        nan        nan 0.81434434 0.81429426        nan        nan\n",
      " 0.81518425 0.81513373        nan        nan 0.81955961 0.81980026\n",
      "        nan        nan 0.81985401 0.8199766         nan        nan\n",
      " 0.81838209 0.8184752         nan        nan 0.81912895 0.81920307\n",
      "        nan        nan 0.83778488 0.83772523        nan        nan\n",
      " 0.8374829  0.8374829         nan        nan 0.83754569 0.83754569\n",
      "        nan        nan 0.83754228 0.83754228        nan        nan\n",
      " 0.83861843 0.83866484        nan        nan 0.83779043 0.8377673\n",
      "        nan        nan 0.83807546 0.83807585        nan        nan\n",
      " 0.83803697 0.83803736        nan        nan 0.84039673 0.84037838\n",
      "        nan        nan 0.84024819 0.84020972        nan        nan\n",
      " 0.84073516 0.84067541        nan        nan 0.84073627 0.84067623\n",
      "        nan        nan 0.83782433 0.83776287        nan        nan\n",
      " 0.83733141 0.83750653        nan        nan 0.8374025  0.83757632\n",
      "        nan        nan 0.83740587 0.83740587        nan        nan\n",
      " 0.83862204 0.83862204        nan        nan 0.83777994 0.83777994\n",
      "        nan        nan 0.83805914 0.83805914        nan        nan\n",
      " 0.8380632  0.8380632         nan        nan 0.8405756  0.84046818\n",
      "        nan        nan 0.84036359 0.84029044        nan        nan\n",
      " 0.84088275 0.84077723        nan        nan 0.84083789 0.84078092]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.120e+01, tolerance: 1.022e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(imputation_method='mean',\n",
       "                                                          variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'Mi...\n",
       "                                        SmartCorrelatedSelection(selection_method='variance')),\n",
       "                                       ('Lasso', Lasso(random_state=0))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'Lasso__alpha': (1, 0),\n",
       "                          'Lasso__max_iter': [10, 100, 1000],\n",
       "                          'discretiser__bins': [8, 10, 12],\n",
       "                          'encoder__top_categories': [5, 7, 10, None],\n",
       "                          'imputer_cat__imputation_method': ['frequent',\n",
       "                                                             'missing'],\n",
       "                          'imputer_num__imputation_method': ['mean',\n",
       "                                                             'median']}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d1151334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R2 score train set:0.8998073370527887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso R2 score train set:0.8068491798971691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\one_hot.py:236: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X[str(feature) + \"_\" + str(category)] = np.where(\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('Lasso', lasso_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('Lasso', lasso_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bfc0f760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lasso__alpha': 0,\n",
       " 'Lasso__max_iter': 1000,\n",
       " 'discretiser__bins': 12,\n",
       " 'encoder__top_categories': 10,\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'mean'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ffa0fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xgb = Pipeline([('imputer_num', MeanMedianImputer(imputation_method='mean', variables = num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables = cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3, variables = cat_list)),\n",
    "                 ('discretiser', EqualWidthDiscretiser(bins = 10, variables = num_list)),\n",
    "                 ('encoder', OrdinalEncoder(variables= cat_list)),\n",
    "                 ('scaler', SklearnTransformerWrapper(transformer= StandardScaler(), variables = num_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998)),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('XGB', XGBRegressor (random_state = 0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "929e11b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = [{\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'discretiser__bins': [8, 10, 12],\n",
    "    'encoder__encoding_method': ['arbitrary', 'ordered'],\n",
    "    'XGB__n_estimators': [100, 150], \n",
    "    'XGB__max_depth': [2, 3, 4, 5], \n",
    "    'XGB__learning_rate': [0.01, 0.05, 1] \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1c705f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_search = GridSearchCV(estimator=pipe_xgb, param_grid = xgb_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "df0b933a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "288 fits failed out of a total of 2880.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "288 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5586633  0.5586633         nan        nan\n",
      " 0.55778566 0.55778566        nan        nan 0.55335422 0.55388351\n",
      "        nan        nan 0.55400477 0.55521055        nan        nan\n",
      " 0.55452241 0.55452241        nan        nan 0.5548253  0.5548253\n",
      "        nan        nan 0.68175382 0.68175382        nan        nan\n",
      " 0.68163245 0.68163245        nan        nan 0.67621392 0.6772026\n",
      "        nan        nan 0.6761887  0.67781153        nan        nan\n",
      " 0.67465143 0.67465143        nan        nan 0.67612059 0.67612059\n",
      "        nan        nan 0.60371567 0.60371567        nan        nan\n",
      " 0.60488824 0.60488824        nan        nan 0.59949924 0.59816748\n",
      "        nan        nan 0.60058577 0.59884091        nan        nan\n",
      " 0.60278905 0.60277742        nan        nan 0.60373282 0.60377406\n",
      "        nan        nan 0.72469196 0.72469196        nan        nan\n",
      " 0.72692169 0.72692169        nan        nan 0.71920809 0.71920809\n",
      "        nan        nan 0.72075227 0.72075227        nan        nan\n",
      " 0.72054208 0.72065519        nan        nan 0.7218846  0.72210558\n",
      "        nan        nan 0.63001017 0.63001017        nan        nan\n",
      " 0.63045993 0.63045993        nan        nan 0.62285676 0.62311411\n",
      "        nan        nan 0.62552617 0.62504507        nan        nan\n",
      " 0.62825155 0.62820037        nan        nan 0.62753833 0.62796924\n",
      "        nan        nan 0.74254356 0.74254356        nan        nan\n",
      " 0.74205285 0.74205285        nan        nan 0.73765548 0.73765548\n",
      "        nan        nan 0.74208379 0.74208379        nan        nan\n",
      " 0.74039338 0.74023854        nan        nan 0.73971683 0.74010016\n",
      "        nan        nan 0.6423479  0.6423479         nan        nan\n",
      " 0.64244583 0.64244583        nan        nan 0.63851944 0.63858132\n",
      "        nan        nan 0.64328739 0.64329313        nan        nan\n",
      " 0.64451988 0.64452746        nan        nan 0.6452201  0.64502052\n",
      "        nan        nan 0.75355356 0.75355356        nan        nan\n",
      " 0.75457187 0.75457187        nan        nan 0.74950998 0.74958363\n",
      "        nan        nan 0.75448281 0.75445432        nan        nan\n",
      " 0.75375809 0.75357668        nan        nan 0.75684529 0.75618316\n",
      "        nan        nan 0.83015908 0.83015908        nan        nan\n",
      " 0.82922711 0.82922711        nan        nan 0.83562817 0.83562817\n",
      "        nan        nan 0.83721719 0.83721719        nan        nan\n",
      " 0.82878961 0.82824917        nan        nan 0.82972585 0.82993385\n",
      "        nan        nan 0.83460005 0.83460005        nan        nan\n",
      " 0.83502718 0.83502718        nan        nan 0.84764999 0.84764999\n",
      "        nan        nan 0.84995939 0.84995939        nan        nan\n",
      " 0.83814624 0.83803827        nan        nan 0.83820081 0.83864613\n",
      "        nan        nan 0.84170663 0.84170663        nan        nan\n",
      " 0.84457988 0.84457988        nan        nan 0.84562139 0.84562139\n",
      "        nan        nan 0.84799295 0.84799295        nan        nan\n",
      " 0.84282751 0.84258635        nan        nan 0.84598443 0.84515297\n",
      "        nan        nan 0.8454697  0.8454697         nan        nan\n",
      " 0.84715882 0.84715882        nan        nan 0.85084314 0.85084314\n",
      "        nan        nan 0.85469165 0.85469165        nan        nan\n",
      " 0.84890009 0.84835294        nan        nan 0.8525041  0.85232025\n",
      "        nan        nan 0.84853617 0.84853617        nan        nan\n",
      " 0.84671822 0.84671822        nan        nan 0.85155793 0.85031797\n",
      "        nan        nan 0.85642596 0.85537343        nan        nan\n",
      " 0.84871068 0.84833997        nan        nan 0.85046705 0.85126114\n",
      "        nan        nan 0.8502511  0.8502511         nan        nan\n",
      " 0.85057236 0.85057236        nan        nan 0.85527971 0.85444835\n",
      "        nan        nan 0.85923327 0.85880318        nan        nan\n",
      " 0.85272306 0.85211389        nan        nan 0.85621576 0.85708951\n",
      "        nan        nan 0.84960457 0.84960457        nan        nan\n",
      " 0.85340197 0.85340197        nan        nan 0.84865038 0.84865038\n",
      "        nan        nan 0.85909117 0.85890485        nan        nan\n",
      " 0.84852686 0.84936133        nan        nan 0.85555165 0.85485263\n",
      "        nan        nan 0.85243277 0.85243277        nan        nan\n",
      " 0.85663708 0.85663708        nan        nan 0.85356068 0.85188854\n",
      "        nan        nan 0.86363718 0.86117172        nan        nan\n",
      " 0.85164455 0.85250583        nan        nan 0.85791964 0.85773745\n",
      "        nan        nan 0.78426158 0.78426158        nan        nan\n",
      " 0.76846428 0.76846428        nan        nan 0.78307009 0.78307009\n",
      "        nan        nan 0.78918012 0.78899526        nan        nan\n",
      " 0.77084667 0.76394033        nan        nan 0.74686419 0.75686961\n",
      "        nan        nan 0.78132163 0.78132163        nan        nan\n",
      " 0.76237923 0.76237923        nan        nan 0.78436827 0.7875059\n",
      "        nan        nan 0.78721478 0.78433229        nan        nan\n",
      " 0.76420707 0.75523279        nan        nan 0.74938937 0.75954083\n",
      "        nan        nan 0.77003981 0.77003981        nan        nan\n",
      " 0.7690645  0.7690645         nan        nan 0.72302176 0.72337239\n",
      "        nan        nan 0.72816022 0.73834946        nan        nan\n",
      " 0.76616313 0.76700772        nan        nan 0.7476746  0.73676877\n",
      "        nan        nan 0.76885662 0.76885662        nan        nan\n",
      " 0.76916481 0.76916481        nan        nan 0.72382395 0.71976809\n",
      "        nan        nan 0.7346794  0.72605758        nan        nan\n",
      " 0.76610744 0.76531212        nan        nan 0.74631324 0.73594306\n",
      "        nan        nan 0.70955192 0.70955192        nan        nan\n",
      " 0.73473749 0.73473749        nan        nan 0.72434757 0.72707834\n",
      "        nan        nan 0.73259306 0.71646649        nan        nan\n",
      " 0.75632639 0.74658261        nan        nan 0.73079408 0.73359997\n",
      "        nan        nan 0.70920937 0.70920937        nan        nan\n",
      " 0.73405217 0.73405217        nan        nan 0.72399205 0.72687254\n",
      "        nan        nan 0.7319002  0.71594834        nan        nan\n",
      " 0.75607247 0.74613774        nan        nan 0.73084452 0.73325702\n",
      "        nan        nan 0.71856167 0.71856167        nan        nan\n",
      " 0.73992647 0.73992647        nan        nan 0.73381897 0.72096236\n",
      "        nan        nan 0.7304985  0.73145686        nan        nan\n",
      " 0.72467204 0.73041549        nan        nan 0.72188515 0.7299504\n",
      "        nan        nan 0.71837347 0.71837347        nan        nan\n",
      " 0.73984905 0.73984905        nan        nan 0.72217449 0.73232096\n",
      "        nan        nan 0.73040448 0.73136491        nan        nan\n",
      " 0.72467762 0.73044021        nan        nan 0.72184703 0.7299372 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(imputation_method='mean',\n",
       "                                                          variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'Mi...\n",
       "                                                     validate_parameters=None,\n",
       "                                                     verbosity=None))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'XGB__learning_rate': [0.01, 0.05, 1],\n",
       "                          'XGB__max_depth': [2, 3, 4, 5],\n",
       "                          'XGB__n_estimators': [100, 150],\n",
       "                          'discretiser__bins': [8, 10, 12],\n",
       "                          'encoder__encoding_method': ['arbitrary', 'ordered'],\n",
       "                          'imputer_cat__imputation_method': ['frequent',\n",
       "                                                             'missing'],\n",
       "                          'imputer_num__imputation_method': ['mean',\n",
       "                                                             'median']}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "9c71c003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB R2 score train set:0.9831465638209311\n",
      "XGB R2 score train set:0.8674215117040147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('XGB', xgb_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('XGB', xgb_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "72bdfc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGB__learning_rate': 0.05,\n",
       " 'XGB__max_depth': 5,\n",
       " 'XGB__n_estimators': 150,\n",
       " 'discretiser__bins': 10,\n",
       " 'encoder__encoding_method': 'ordered',\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'mean'}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "811755dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_svr = Pipeline([('imputer_num', MeanMedianImputer(imputation_method='mean', variables = num_list)),\n",
    "                 ('imputer_cat', CategoricalImputer(imputation_method= 'frequent', variables = cat_list)),\n",
    "                 ('rare_label', RareLabelEncoder(tol = 0.05, n_categories = 3, variables = cat_list)),\n",
    "                 ('discretiser', EqualWidthDiscretiser(bins = 10, variables = num_list)),\n",
    "                 ('encoder', OrdinalEncoder(variables= cat_list)),\n",
    "                 ('scaler', SklearnTransformerWrapper(transformer= StandardScaler(), variables = num_list)),\n",
    "                 ('constant', DropConstantFeatures(tol = 0.998)),\n",
    "                 ('duplicated', DropDuplicateFeatures()),\n",
    "                 ('correlated', SmartCorrelatedSelection(selection_method = 'variance')),\n",
    "                 ('SVR', SVR ())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "17fadb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_param_grid = [{\n",
    "    'imputer_num__imputation_method':['mean','median'],\n",
    "    'imputer_cat__imputation_method':['frequent', 'missing'],\n",
    "    'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
    "    'discretiser__bins': [8, 10, 12],\n",
    "    'SVR__kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'SVR__gamma' : ['auto','scale']\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "96103f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_grid_search = GridSearchCV(estimator=pipe_svr, param_grid = svr_param_grid, cv = 5, n_jobs = -1, scoring = 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "29061c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "96 fits failed out of a total of 960.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "96 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 390, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 348, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\base.py\", line 855, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "  File \"C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\imputation\\categorical.py\", line 151, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Variable Foundation contains multiple frequent categories.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [         nan          nan   0.84274138   0.84274138          nan\n",
      "          nan   0.85119982   0.85119982          nan          nan\n",
      "   0.84390335   0.84384547          nan          nan   0.85474889\n",
      "   0.85487563          nan          nan   0.84619344   0.84628833\n",
      "          nan          nan   0.85640818   0.85641431          nan\n",
      "          nan   0.82673919   0.82673919          nan          nan\n",
      "   0.72095875   0.72095875          nan          nan   0.82966017\n",
      "   0.82959228          nan          nan   0.72675983   0.72674095\n",
      "          nan          nan   0.84534773   0.84586478          nan\n",
      "          nan   0.75509752   0.75509395          nan          nan\n",
      "   0.82004672   0.82004672          nan          nan   0.81842794\n",
      "   0.81842794          nan          nan   0.82087814   0.82088502\n",
      "          nan          nan   0.82065762   0.82065316          nan\n",
      "          nan   0.81739133   0.81723701          nan          nan\n",
      "   0.81864002   0.81887749          nan          nan -17.54475808\n",
      " -17.54475808          nan          nan -26.5412438  -26.5412438\n",
      "          nan          nan -17.63314111 -17.62588384          nan\n",
      "          nan -26.99919637 -26.88410847          nan          nan\n",
      " -17.11791376 -17.13267781          nan          nan -27.07092356\n",
      " -27.10052032          nan          nan   0.84274138   0.84274138\n",
      "          nan          nan   0.85119982   0.85119982          nan\n",
      "          nan   0.84484035   0.84384547          nan          nan\n",
      "   0.85474889   0.85487563          nan          nan   0.84619344\n",
      "   0.84628833          nan          nan   0.85640818   0.85641431\n",
      "          nan          nan   0.85761233   0.85761233          nan\n",
      "          nan   0.72738004   0.72738004          nan          nan\n",
      "   0.85975214   0.86066073          nan          nan   0.73361547\n",
      "   0.7335821           nan          nan   0.86990855   0.87013791\n",
      "          nan          nan   0.7586492    0.7586724           nan\n",
      "          nan   0.84400209   0.84400209          nan          nan\n",
      "   0.83221346   0.83221346          nan          nan   0.84349275\n",
      "   0.84484455          nan          nan   0.83392516   0.834085\n",
      "          nan          nan   0.8431719    0.8430131           nan\n",
      "          nan   0.83138773   0.83164397          nan          nan\n",
      "  -3.0753204   -3.0753204           nan          nan -11.71705383\n",
      " -11.71705383          nan          nan  -3.0871262   -3.07752572\n",
      "          nan          nan -12.148214   -12.1161731           nan\n",
      "          nan  -3.01559434  -3.02062627          nan          nan\n",
      " -12.41904619 -12.4377942 ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Street is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable Utilities is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable LandSlope is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable CentralAir is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\encoding\\rare_label.py:161: UserWarning: The number of unique categories for variable PavedDrive is less than that indicated in n_categories. Thus, all categories will be considered frequent\n",
      "  warnings.warn(\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n",
      "C:\\Users\\kmk\\anaconda3\\envs\\AI\\lib\\site-packages\\feature_engine\\selection\\smart_correlation_selection.py:291: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  f = X[feature_group].std().sort_values(ascending=False).index[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('imputer_num',\n",
       "                                        MeanMedianImputer(imputation_method='mean',\n",
       "                                                          variables=['LotFrontage',\n",
       "                                                                     'LotArea',\n",
       "                                                                     'YearBuilt',\n",
       "                                                                     'YearRemodAdd',\n",
       "                                                                     'MasVnrArea',\n",
       "                                                                     'BsmtFinSF1',\n",
       "                                                                     'BsmtFinSF2',\n",
       "                                                                     'BsmtUnfSF',\n",
       "                                                                     'TotalBsmtSF',\n",
       "                                                                     '1stFlrSF',\n",
       "                                                                     '2ndFlrSF',\n",
       "                                                                     'GrLivArea',\n",
       "                                                                     'GarageYrBlt',\n",
       "                                                                     'GarageArea',\n",
       "                                                                     'WoodDeckSF',\n",
       "                                                                     'OpenPorchSF',\n",
       "                                                                     'EnclosedPorch',\n",
       "                                                                     'ScreenPorch',\n",
       "                                                                     'Mi...\n",
       "                                        SmartCorrelatedSelection(selection_method='variance')),\n",
       "                                       ('SVR', SVR())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'SVR__gamma': ('auto', 'scale'),\n",
       "                          'SVR__kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
       "                          'discretiser__bins': [8, 10, 12],\n",
       "                          'encoder__encoding_method': ['ordered', 'arbitrary'],\n",
       "                          'imputer_cat__imputation_method': ['frequent',\n",
       "                                                             'missing'],\n",
       "                          'imputer_num__imputation_method': ['mean',\n",
       "                                                             'median']}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6c2fe313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR R2 score train set:0.9718914643218043\n",
      "SVR R2 score train set:0.8629447195258513\n"
     ]
    }
   ],
   "source": [
    "print(\"{} R2 score train set:{}\".format('SVR', svr_grid_search.score(x_train, y_train)))\n",
    "print(\"{} R2 score train set:{}\".format('SVR', svr_grid_search.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d3fa3785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVR__gamma': 'scale',\n",
       " 'SVR__kernel': 'poly',\n",
       " 'discretiser__bins': 12,\n",
       " 'encoder__encoding_method': 'ordered',\n",
       " 'imputer_cat__imputation_method': 'missing',\n",
       " 'imputer_num__imputation_method': 'median'}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9e6c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
